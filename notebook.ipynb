{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(filename='file.log',level=logging.DEBUG,format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadData(trainingFile, testingFile):\n",
    "    logging.info('loading the data....')\n",
    "    def convertDataframe(inputFile):\n",
    "    \n",
    "        data = pd.DataFrame(columns=range(100000))\n",
    "        logging.info(\"created an empty dataframe of 100000 features\")    \n",
    "        for i in range(len(inputFile)):\n",
    "            record = np.fromstring(inputFile[i], dtype=int, sep=' ')\n",
    "            record_bool = [0 for j in range(100000)]\n",
    "            for col in record:\n",
    "                record_bool[col-1] = 1\n",
    "            \n",
    "            data.loc[i] = record_bool\n",
    "        logging.info('all the entries are pushed into the dataframe successfully')    \n",
    "        return data\n",
    "    \n",
    "    with open(trainingFile, \"r\") as fr1:\n",
    "        trainFile = fr1.readlines()\n",
    "    \n",
    "    #Split each line in the two files into label and data  \n",
    "    train_data_list = []\n",
    "    train_labels_list = []\n",
    "    \n",
    "    for inputData in trainFile:\n",
    "        train_labels_list.append(inputData[0])\n",
    "        \n",
    "        #Remove the activity label (0/1) and new line character from each record\n",
    "        inputData = inputData.replace(\"0\\t\", \"\")\n",
    "        inputData = inputData.replace(\"1\\t\", \"\")\n",
    "        inputData = inputData.replace(\"\\n\", \"\")\n",
    "        train_data_list.append(inputData)\n",
    "    \n",
    "    train_labels = np.asarray(train_labels_list)\n",
    "    train_data = convertDataframe(train_data_list)\n",
    "        \n",
    "    with open(testingFile, \"r\") as fr2:\n",
    "        testFile = fr2.readlines()\n",
    "    \n",
    "    test_data = convertDataframe(testFile)\n",
    "    logging.info('all the files are loaded successfully and splitted into train data, valid and train label')        \n",
    "    return train_data, test_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data,train_label = loadData('dorothea_train.data','dorothea_valid.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99990</th>\n",
       "      <th>99991</th>\n",
       "      <th>99992</th>\n",
       "      <th>99993</th>\n",
       "      <th>99994</th>\n",
       "      <th>99995</th>\n",
       "      <th>99996</th>\n",
       "      <th>99997</th>\n",
       "      <th>99998</th>\n",
       "      <th>99999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 100000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2      3      4      5      6      7      8      9      \\\n",
       "0        0      0      0      0      0      0      0      0      0      0   \n",
       "1        0      0      0      0      0      0      0      0      0      0   \n",
       "2        0      0      0      0      0      0      0      0      0      0   \n",
       "3        0      0      0      0      0      0      0      0      0      0   \n",
       "4        0      0      0      0      0      0      0      0      0      0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "345      0      0      0      0      0      0      0      0      0      0   \n",
       "346      0      0      0      0      0      0      0      0      0      0   \n",
       "347      0      0      0      0      0      0      0      0      0      0   \n",
       "348      0      0      0      0      0      0      0      0      1      0   \n",
       "349      0      0      0      0      0      0      0      0      0      1   \n",
       "\n",
       "     ...  99990  99991  99992  99993  99994  99995  99996  99997  99998  99999  \n",
       "0    ...      0      0      0      0      0      0      0      0      0      0  \n",
       "1    ...      0      0      0      0      0      0      0      0      0      0  \n",
       "2    ...      0      0      0      0      0      0      0      0      0      0  \n",
       "3    ...      0      0      0      0      0      0      0      0      0      0  \n",
       "4    ...      0      0      0      0      0      0      0      0      0      0  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "345  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "346  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "347  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "348  ...      0      0      0      0      0      0      0      1      0      0  \n",
       "349  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[350 rows x 100000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler((0,1))\n",
    "train_data=scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_data=scaler.fit_transform(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "logging.info('decomposing our data into 5 components')\n",
    "decomposer = PCA(n_components=5)\n",
    "train_data = decomposer.fit_transform(train_data)\n",
    "valid_data=decomposer.fit_transform(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('dorothea_train.labels','r')\n",
    "train_label = [int(i[:-1]) for i in f.readlines()]\n",
    "train_label = np.array(train_label)\n",
    "train_label[train_label==-1]=0\n",
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('dorothea_valid.labels','r')\n",
    "valid_label = [int(i[:-1]) for i in f.readlines()]\n",
    "valid_label = np.array(valid_label)\n",
    "valid_label[valid_label==-1]=0\n",
    "valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12591203,  0.12833059, -0.10287597, -0.31350669, -0.15629315])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# logging.info('checking our model with logistic regression')\n",
    "# model = LogisticRegression()\n",
    "# model.fit(train_data,train_label)\n",
    "# logging.info('model fitted successfully ')\n",
    "# train_pred = model.predict(train_data)\n",
    "# valid_pred=model.predict(valid_data)\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "# logging.info(f'This is for train metrix \\n{confusion_matrix(train_label,train_pred)}')\n",
    "# logging.info(f'this is for testing metrix \\n{confusion_matrix(valid_label,valid_pred)}')\n",
    "# logging.info(f\"This is f1 score for train data: {f1_score(train_label,train_pred)}\")\n",
    "# logging.info(f\"This is f1 score for valid data: {f1_score(valid_label,valid_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <p style='color:red'>  DECISION TREE </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# model2=KNeighborsClassifier\n",
    "# logging.info('checking our model with KNeighbors CLASSIFIER')\n",
    "# knn=model2(n_neighbors=7)\n",
    "# knn.fit(train_data,train_label)\n",
    "# logging.info('model fitted successfully ')\n",
    "# train_pred = knn.predict(train_data)\n",
    "# valid_pred=knn.predict(valid_data)\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "# logging.info(f'This is for train metrix \\n{confusion_matrix(train_label,train_pred)}')\n",
    "# logging.info(f'this is for testing metrix \\n{confusion_matrix(valid_label,valid_pred)}')\n",
    "# logging.info(f\"This is f1 score for train data: {f1_score(train_label,train_pred)}\")\n",
    "# logging.info(f\"This is f1 score for valid data: {f1_score(valid_label,valid_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12591203,  0.12833059, -0.10287597, -0.31350669, -0.15629315])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# model3=DecisionTreeClassifier()\n",
    "# logging.info('checking our model with DECISION TREE CLASSIFIER')\n",
    "# model3.fit(train_data,train_label)\n",
    "# logging.info('model fitted successfully ')\n",
    "# train_pred = model3.predict(train_data)\n",
    "# valid_pred=model3.predict(valid_data)\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "# logging.info(f'This is for train metrix \\n{confusion_matrix(train_label,train_pred)}')\n",
    "# logging.info(f'this is for testing metrix \\n{confusion_matrix(valid_label,valid_pred)}')\n",
    "# logging.info(f\"This is f1 score for train data: {f1_score(train_label,train_pred)}\")\n",
    "# logging.info(f\"This is f1 score for valid data: {f1_score(valid_label,valid_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# model4=SVC()\n",
    "# logging.info('checking our model with SVM CLASSIFIER')\n",
    "# model4.fit(train_data,train_label)\n",
    "# logging.info('model fitted successfully ')\n",
    "# train_pred = model4.predict(train_data)\n",
    "# valid_pred=model4.predict(valid_data)\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "# logging.info(f'This is for train metrix \\n{confusion_matrix(train_label,train_pred)}')\n",
    "# logging.info(f'this is for testing metrix \\n{confusion_matrix(valid_label,valid_pred)}')\n",
    "# logging.info(f\"This is f1 score for train data: {f1_score(train_label,train_pred)}\")\n",
    "# logging.info(f\"This is f1 score for valid data: {f1_score(valid_label,valid_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, counts = np.unique(train_label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 occurs 722 times\n",
      "1 occurs 78 times\n"
     ]
    }
   ],
   "source": [
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value} occurs {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# def find_best_hyperparameters(X, y, param_grid, n_splits=5, random_state=42):\n",
    "\n",
    "#   # Create a StratifiedKFold object\n",
    "#   skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "#   # Create a Random Forest Classifier\n",
    "#   rf_classifier = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "#   # Create a Grid Search CV object\n",
    "#   grid_search = GridSearchCV(estimator=rf_classifier, \n",
    "#                              param_grid=param_grid, \n",
    "#                              cv=skf, \n",
    "#                              scoring='accuracy', \n",
    "#                              n_jobs=-1) \n",
    "\n",
    "#   # Fit the Grid Search CV object to the data\n",
    "#   grid_search.fit(X, y)\n",
    "\n",
    "#   # Get the best hyperparameters and score\n",
    "#   best_params = grid_search.best_params_\n",
    "#   best_score = grid_search.best_score_\n",
    "\n",
    "#   return best_params, best_score\n",
    "\n",
    "# # Example usage\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# # Find the best hyperparameters\n",
    "# best_params, best_score = find_best_hyperparameters(train_data, train_label, param_grid)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Cross-Validation Score:\",best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model5=RandomForestClassifier(n_estimators=300,max_depth=5)\n",
    "# logging.info('checking our model with RANDOM FOREST')\n",
    "# model5.fit(train_data,train_label)\n",
    "# logging.info('model fitted successfully ')\n",
    "# train_pred = model5.predict(train_data)\n",
    "# valid_pred=model5.predict(valid_data)\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "# logging.info(f'This is for train metrix \\n{confusion_matrix(train_label,train_pred)}')\n",
    "# logging.info(f'this is for testing metrix \\n{confusion_matrix(valid_label,valid_pred)}')\n",
    "# logging.info(f\"This is f1 score for train data: {f1_score(train_label,train_pred)}\")\n",
    "# logging.info(f\"This is f1 score for valid data: {f1_score(valid_label,valid_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def find_best_hyperparameters(X, y, model_name, param_grid, n_splits=10, random_state=42):\n",
    "  \"\"\"\n",
    "  Finds the best hyperparameters for a given model using Grid Search CV.\n",
    "\n",
    "  Args:\n",
    "    X: Features (independent variables).\n",
    "    y: Target variable (dependent variable).\n",
    "    model_name: Name of the model ('logistic_regression', 'decision_tree', \n",
    "                'random_forest', 'knn', 'svc').\n",
    "    param_grid: Dictionary of hyperparameters to tune and their possible values.\n",
    "    n_splits: Number of folds for cross-validation.\n",
    "    random_state: Seed for reproducibility.\n",
    "\n",
    "  Returns:\n",
    "    best_params: Dictionary containing the best hyperparameters found.\n",
    "    best_score: Best cross-validation score.\n",
    "  \"\"\"\n",
    "\n",
    "  skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "  if model_name == 'logistic_regression':\n",
    "    model = LogisticRegression()\n",
    "  elif model_name == 'decision_tree':\n",
    "    model = DecisionTreeClassifier(random_state=random_state,max_features=5)\n",
    "  elif model_name == 'random_forest':\n",
    "    model = RandomForestClassifier(random_state=random_state)\n",
    "  elif model_name == 'knn':\n",
    "    model = KNeighborsClassifier()\n",
    "  elif model_name == 'svc':\n",
    "    model = SVC(random_state=random_state)\n",
    "  else:\n",
    "    raise ValueError(\"Invalid model_name. Choose from 'logistic_regression', 'decision_tree', 'random_forest', 'knn', 'svc'.\")\n",
    "\n",
    "  grid_search = GridSearchCV(estimator=model, \n",
    "                             param_grid=param_grid, \n",
    "                             cv=skf, \n",
    "                             scoring='f1', \n",
    "                             n_jobs=-1)\n",
    "\n",
    "  grid_search.fit(X, y)\n",
    "  best_params = grid_search.best_params_\n",
    "  best_score = grid_search.best_score_\n",
    "\n",
    "  return best_params, best_score\n",
    "\n",
    "# Example usage\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    #'logistic_regression': {'C':[i for i in range(1,3)],'penalty':['l2'],'solver':['lbfgs', 'liblinear']},\n",
    "    #'decision_tree': {'max_depth': [i for i in range(1,7)], 'min_samples_split': [i for i in range(2,7)], 'min_samples_leaf': [i for i in range(1,7)],'max_leaf_nodes':[i for i in range(2,7)],'criterion':[\"gini\", \"entropy\", \"log_loss\"] , 'splitter':[\"best\", \"random\"]},\n",
    "     'random_forest': {'n_estimators': [i for i in range(1000)], 'max_depth': [i for i in range(2,7)],'min_samples_split': [i for i in range(2,10)], 'min_samples_leaf': [i for i in range(1,7)],'max_leaf_nodes':[i for i in range(2,7)],'criterion':[\"gini\", \"entropy\", \"log_loss\"]},\n",
    "     'knn': {'n_neighbors': [i for i in range(20)],\"weights\":['uniform','distance'],\"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute'],\"leaf_size\":[i for i in range(100)],'p':[1,2]},\n",
    "    # 'svc': {'C': [i for i in range(100)], \"kernel\":['linear','poly', 'rbf', 'sigmoid', 'precomputed'],'degree':[i for i in range(10)],'gamma':['scale','auto'],'probability':[True,False]}\n",
    "}\n",
    "\n",
    "# Find best hyperparameters for each model\n",
    "for model_name, param_grid in param_grids.items():\n",
    "  best_params, best_score = find_best_hyperparameters(train_data, train_label, model_name, param_grid)\n",
    "  print(f\"Best Hyperparameters for {model_name}:\", best_params)\n",
    "  print(f\"Best Cross-Validation Score for {model_name}:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters for logistic_regression: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "Best Cross-Validation Score for logistic_regression: 0.28391053391053395\n",
    "Best Hyperparameters for decision_tree: {'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
    "Best Cross-Validation Score for decision_tree: 0.5787435500515996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
